{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# RNN In-Lab Assignments\n",
        "\n",
        "---\n",
        "\n",
        "## **Q 1 — Building RNN, LSTM, and GRU from Scratch**\n",
        "\n",
        "### Objective\n",
        "Implement fundamental recurrent architectures from scratch to understand their internal mechanics.\n",
        "\n",
        "### Tasks\n",
        "1. Implement a simple RNN using NumPy/Tensorflow/Pytorch:\n",
        "   - Include forward pass and backpropagation through time.\n",
        "2. Extend the implementation to include LSTM and GRU units.\n",
        "3. Train all three models on a toy sequential dataset:\n",
        "   - Options: character-level text generation or sine wave prediction.\n",
        "4. Plot and compare training loss curves.\n",
        "5. Write short insights on which model learns faster and why.\n",
        "6. Visualize gradient magnitudes across time steps to demonstrate vanishing/exploding gradients.(Optional)\n",
        "---\n",
        "\n",
        "## **Q 2 — Training and Weight Visualization**\n",
        "\n",
        "### Objective\n",
        "Train RNN, LSTM, and GRU models on a real dataset and study how their weights evolve during learning.\n",
        "\n",
        "### Tasks\n",
        "1. Train RNN, LSTM, and GRU models using PyTorch or TensorFlow on one of the following:\n",
        "   - Sequential MNIST\n",
        "   - IMDb Sentiment Analysis\n",
        "   - Time series dataset (e.g., stock prices, temperature)\n",
        "2. Save model weights after each epoch.\n",
        "3. Visualize weight distributions across epochs using histograms or kernel density plots.\n",
        "4. Compare how weight evolution differs between RNN, LSTM, and GRU.\n",
        "5. Discuss observations related to training stability, saturation, and convergence behavior.\n",
        "\n",
        "---\n",
        "\n",
        "## **Q 3 — Visual Question Answering (VQA) with CNN + RNN Fusion (No Training)**\n",
        "\n",
        "### Objective\n",
        "Understand multimodal representation fusion by combining CNN (for images) and RNN variants (for questions), without training.\n",
        "\n",
        "### Tasks\n",
        "1. Use a pretrained CNN (e.g., ResNet18) to extract image feature vectors for VQA v2 dataset or COCO-QA.\n",
        "2. Use an RNN/LSTM/GRU to encode natural language questions into hidden representations.\n",
        "3. Visualize RNN hidden-state dynamics:\n",
        "   - Plot PCA or t-SNE trajectories of hidden states across time.\n",
        "   - Generate similarity heatmaps between hidden states of different words.\n",
        "4. Fuse image and question embeddings:\n",
        "   - Compute cosine similarities between question embeddings and image features.\n",
        "   - Visualize similarities using heatmaps or bar charts.\n",
        "5. Compare visualizations for RNN, LSTM, and GRU encoders and describe qualitative differences.\n",
        "\n",
        "---\n",
        "\n",
        "### **Submission Requirements**\n",
        "- .ipynb notebook\n",
        "- An explanation summarizing observations and key visualizations.\n",
        "- Notebooks or scripts implementing each question.\n",
        "- Plots and figures for analysis and discussion.\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "fmUutTvqfFe_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D0ifSXGQfHKa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}